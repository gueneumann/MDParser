GN: DECEMBER, 2014:

- define main method for training, testing and evaluation
	/MDP/src/de/dfki/lt/mdparser/test/CompleteTrainParseEval.java
-> DONE

	
January, 2016:

New maven project:
- make a maven project MDParser
-> DONE

- make it on github
-> DONE

- make sure to use same version for liblinear for GNT and MDP
-> DONE

Feb, 2017:

-> defined non-parallel versions for training and application
-> DONE

- remove MorphAdorner -> use GNT GntTextSegmentizer instead -> DONE

- remove reference to nemex -> DONE

- remove reference to SVN tagger via Nereid -> use GNT tagger instead -> DONE

- remove or adapt sentence splitter or move to Gnt -> DONE

- clean code -> DONE

- log file -> DONE

- properties for training with MDParser and POS

- github wiki docu -> DONE

Improve MDP:

From paper "Optimizing Dependency Parsing Throughput“
-	MDParser transforms String features to integer values since the used liblinear classifier operates on numerical values. 
	This step requires a total of 27 transformations for every word, since MDParser computes 27 different features templates. 
	Syntactic Parser, in contrast, transforms elementary features to integer values before the features are combined, 
	requiring only three transformations (part-of-speech, word form and dependency) for every word in a sentence.
-	Syntactic Parser represents its numerical features n as 64-bit integers (Java long type) which consist of (i) 
	an 8 bit value indicating the feature type, and (ii) one or more of the following elementary features: 
	word forms (20 bit), part-of-speech tag (16 bit) or dependency label (16 bit). 
	The feature type is always stored in the last eight bits, while the position of elementary features 
	depends on the feature type. 
-	We, therefore, replace the mapping M: F -> N of parser feature strings fi \in F 
	to integer values n \in N with three mappings that translate word forms wi \in W 
	(M_wordform: W -> {0, … ,1048575}), part-of-speech tags posi \in P 
	(M_pos: P -> {0, …, 65535}) and dependency labels di \in D 
	(M_dep: D -> {0, …, 65535}) to integer values. 
	The numerical feature value n is then derived by performing bit operations on these elementary features.
-	The test for cycles and projectiveness traverse the dependency tree 
-	assuming that projectiveness is a symmetric property, then only a word pair has to be tested once rather than twice 
	(for potential dependency n_i -> n_j and n_j -> n_i) 
-	We also perform a final optimization step on the trained model which eliminates features with a weight of zero.

-> probably in processCombined()

Comments from Alexander:

Hallo Herr Neumann,

interessant :) MDParser ist noch am Leben :)

Also sie haben wohl:

1) ein paar Feature Templates weggelassen (steht dann aber nicht in den Ergebnissen)
2) seltene Features durch 'unknown'-Werte ersetzt (steht auch nicht in den Ergebnissen was genau das bringt)
3) String-Konkatenationen durch Integer-Multiplikationen ersetzt
4) Andere Reihenfolge bei der Berechnung der Permissibility.

Im Prinzip alles sehr plausibel.
Den Tipp mit den Integer-Multiplikationen hatte ich schon damals erhalten 
als wir Besuch von Google(Slav Petrov) hatten. 
Er wollte/konnte mir jedoch keine Einzelheiten verraten. 

Ich meinte aber die Anwendung von hashCode() ausprobiert zu haben, ohne den im Paper beschriebenen Erfolg. Man muss ja bedenken, 
auch Konkatenationen sind sehr billig, problematisch ist nur ihre Anzahl. 
Durch die Multiplikationen sinkt die Anzahl nicht, daher kann es meiner Meinung nach nicht zum Durchbruch kommen. 

Die anderen Schritte sind sehr glaubwürdig, insbesondere die Experimente mit der Permissibility, ich muss gestehen ich habe nie daran gedacht damit rumzuspielen, erkenne aber jetzt das Potenzial.

Hallo Herr Neumann,

ja im Prinzip sind alle Ideen eher leicht umzusetzen. 
Nur wie gesagt, mit 3) habe ich damals nichts auf die Schnelle hinbekommen, 
vielleicht geht es aber auch ganz einfach.

1) Ja nur nach der Erstellung der Trainingsdaten alle Features durchgehen, 
zählen und die seltenen durch unknown ersetzen. In der Anwendungsphase muss 
man das dann natürlich nicht  mehr machen, entweder ist dann ein Feature häufig und vorhanden 
oder es wird eben keinen Match geben. Ich sehe hier sogar noch mehr Potenzial für Optimierung, 
denn könnte man solche Fälle vorhersagen, wo es sich gar nicht lohnt ein Feature zu konstruieren, 
um dann festzustellen, dass es zu selten ist, dann würde man Zeit sparen. 

4) Muss man für beide Phasen ändern, ich glaube aber in beiden Phasen wird dieselbe Funktion genutzt, 
d.h. im Prinzip wird es nur an einer Stelle geändert und gilt für beide Phasen.


HIERIX:, June, 2018:

MDParser and Morphology
- check how to integrate morphology and stemming

using Universal Dependency UD

add feature functions in de.dfki.lt.mdparser.features.FeatureExtractor

- morph feature from UD (or only some features)
- cluster ID of words: using Marmot

Do ablation tests for features:

- pj is essential feature
  - what else
- check how far WORDs are necessary
- which dynamic features are necessary

- ablation test could be realized by listing all names of existing features and then
  only use those which are listed !
  -> define here: de.dfki.lt.mdparser.features.CovingtonFeatureModel
  
Check de.dfki.lt.mdparser.algorithm.Dependency.isProjective(int[])
- did tests but do not see what it brings

Integrate tracing:
- store in file CONLL trees and feature vectors + labels
- do it for training and testing

On training I only achieve:

Parent accuracy: 0.9210743012439376
Label accuracy:  0.9067333773757602

## MDP dependency analysis on train of iread languages:

Complete testing for 4 languages:
System time (msec): 13201
Lang                 |  UAS   |  LAS   |  Speed tot. 
--------------------------------------------
English              |  91.06 |  89.74 | 
German               |  86.91 |  84.63 | 
Greek                |  90.79 |  89.03 | 
Spanish              |  89.99 |  87.86 | 
--------------------------------------------
Avg                  |  89.69 |  87.81



NOTE:
Liblinear solver is set hard-frozen:

de.dfki.lt.mdparser.parser.TrainWorker.TrainWorker(Alphabet, double)
de.dfki.lt.mdparser.parser.TrainerMemory.trainWithSplittingFromMemory(String, String)

Used defaults:

new Parameter(SolverType.MCSVM_CS, 0.1, 0.3)

(in TrainWorker eps = 0.1 is used, but shows no effect for en-train:
Parent accuracy: 0.9212350247921292
Label accuracy:  0.906892013605144
)


de.dfki.lt.mdparser.parser.TrainerFiles.trainWithSplittingFromDisk(String, String)
de.dfki.lt.mdparser.parser.TrainerMemory.trainWithSplittingFromMemory(String, String)

Used default:

bias = -1

de.dfki.lt.mdparser.parser.Trainer.restoreModels(Path, Alphabet, Path)

Used default:
Uses string of solver type into to model file

NOTE:

In mdparser.pdf Alexander uses L1 regularized logistic regression